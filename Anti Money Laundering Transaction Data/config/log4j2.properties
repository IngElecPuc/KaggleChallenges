# Nivel por defecto (bájalo a INFO/ERROR según gusto)
rootLogger.level = INFO
rootLogger.appenderRefs = rolling
rootLogger.appenderRef.rolling.ref = ROLLING

# Appender a archivo con rotación diaria
appender.rolling.type = RollingFile
appender.rolling.name = ROLLING
appender.rolling.fileName = ${sys:LOG_DIR}/spark-app.log
appender.rolling.filePattern = ${sys:LOG_DIR}/spark-app-%d{yyyy-MM-dd}-%i.log.gz
appender.rolling.layout.type = JsonLayout
appender.rolling.layout.compact = true
appender.rolling.layout.eventEol = true
appender.rolling.policies.type = Policies
appender.rolling.policies.time.type = TimeBasedTriggeringPolicy
appender.rolling.policies.time.interval = 1
appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
appender.rolling.policies.size.size = 50MB
#appender.rolling.strategy.type = DefaultRolloverStrategy
#appender.rolling.strategy.max = 30

# Silencia módulos verbosos si quieres
logger.spark.name = org.apache.spark
logger.spark.level = INFO
logger.spark.additivity = false
logger.spark.appenderRefs = rolling
logger.spark.appenderRef.rolling.ref = ROLLING

logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = WARN
logger.hadoop.additivity = false
logger.hadoop.appenderRefs = rolling
logger.hadoop.appenderRef.rolling.ref = ROLLING

# logger.hadoopnative.name = org.apache.hadoop.util.NativeCodeLoader
# logger.hadoopnative.level = ERROR
# logger.hadoopnative.additivity = false
# logger.hadoopnative.appenderRefs = rolling
# logger.hadoopnative.appenderRef.rolling.ref = ROLLING
