{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70536df9-f4e1-4487-842f-5765b0af9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Experimento de neighbor explosion (dirigido) con Neo4j + py2neo\n",
    "\n",
    "- Muestra N semillas (nodos objetivo)\n",
    "- Para cada semilla, cuenta frontier sizes a 1..L hops (dirigido)\n",
    "- Ajusta dos modelos:\n",
    "  A) log N_l = log a + b * l * log deg_out(seed)\n",
    "  B) log N_l = log alpha + l * log m\n",
    "\"\"\"\n",
    "\n",
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import time\n",
    "\n",
    "# =========================\n",
    "# CONFIGURACIÓN DEL EXPERIMENTO\n",
    "# =========================\n",
    "\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASS = \"Banco.69\"\n",
    "\n",
    "# Dirección del grafo para la expansión:\n",
    "# \"OUT\" para (s)-[*]->(n), \"IN\" para (s)<-[*]-(n), \"BOTH\" para no dirigido.\n",
    "DIRECTION = \"OUT\"\n",
    "\n",
    "# Etiqueta(s) y tipo(s) de arista si quieres restringir (opcional)\n",
    "NODE_LABEL = \"Account\"          # e.g., \"Account\"  (o None para todos)\n",
    "REL_TYPES = \"TX\"           # e.g., [\"TRANSFER\", \"PAYS\"]  (o None para todos)\n",
    "\n",
    "# Semillas y hops\n",
    "N_SEEDS = 1000             # número de semillas a muestrear\n",
    "MAX_HOPS = 3               # p.ej. 3 o 4\n",
    "REPEAT_EXPERIMENTS = 1     # si quieres repetir el muestreo varias veces (dejamos 1 = una pasada)\n",
    "\n",
    "# Si tienes APOC y quieres usarlo (un poco más eficiente), pon True\n",
    "USE_APOC = False\n",
    "\n",
    "# Randomize con ORDER BY rand() LIMIT N (simple; suficiente para el experimento)\n",
    "# Si tu grafo es gigantesco y hay sesgo, podrías estratificar por grado o por etiqueta.\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONEXIÓN\n",
    "# =========================\n",
    "\n",
    "graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "\n",
    "# Verifica APOC si quieres usarlo\n",
    "if USE_APOC:\n",
    "    try:\n",
    "        _ = graph.run(\"RETURN apoc.version() AS v\").to_data_frame()\n",
    "    except Exception as e:\n",
    "        print(\"APOC no disponible o no habilitado. Cambiando a Cypher puro.\")\n",
    "        USE_APOC = False\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS DE CYPHER\n",
    "# =========================\n",
    "\n",
    "def cypher_rel_type_pattern(rel_types):\n",
    "    \"\"\"Construye el patrón de tipos de relación para Cypher.\"\"\"\n",
    "    if not rel_types:\n",
    "        return \"\"\n",
    "    # Devuelve: :T1|:T2|:T3\n",
    "    return \":\" + \"|:\".join(rel_types)\n",
    "\n",
    "REL_PATTERN = cypher_rel_type_pattern(REL_TYPES)\n",
    "\n",
    "def seed_query(limit, node_label=None):\n",
    "    if node_label:\n",
    "        return f\"\"\"\n",
    "        MATCH (n:`{node_label}`)\n",
    "        WITH n ORDER BY rand()\n",
    "        LIMIT {limit}\n",
    "        RETURN id(n) AS id\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)\n",
    "        WITH n ORDER BY rand()\n",
    "        LIMIT {limit}\n",
    "        RETURN id(n) AS id\n",
    "        \"\"\"\n",
    "\n",
    "def out_degree_query(node_id, rel_pattern):\n",
    "    # out-degree de la semilla (dirigido saliente)\n",
    "    if rel_pattern:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)-[r{rel_pattern}]->()\n",
    "        WHERE id(n) = {node_id}\n",
    "        RETURN count(r) AS deg\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)-[r]->()\n",
    "        WHERE id(n) = {node_id}\n",
    "        RETURN count(r) AS deg\n",
    "        \"\"\"\n",
    "\n",
    "def frontier_count_cypher(seed_id, hop, direction=\"OUT\", rel_pattern=\"\"):\n",
    "    \"\"\"\n",
    "    Cuenta nodos a distancia EXACTA = hop (no acumulado), dirigidos según 'direction'.\n",
    "    Usamos DISTINCT para evitar repeticiones.\n",
    "    IMPORTANTE: la longitud *hop* se fija en el patrón (no se puede parametrizar directamente).\n",
    "    \"\"\"\n",
    "    if direction.upper() == \"OUT\":\n",
    "        arrow = \"->\"\n",
    "        left = \"-\"\n",
    "        right = \"->\"\n",
    "        pattern = f\"-[r{rel_pattern}*{hop}..{hop}]->\"\n",
    "    elif direction.upper() == \"IN\":\n",
    "        arrow = \"<-\"\n",
    "        left = \"<-\"\n",
    "        right = \"-\"\n",
    "        pattern = f\"<-[r{rel_pattern}*{hop}..{hop}]-\"\n",
    "    else:  # BOTH (no dirigido)\n",
    "        pattern = f\"-[r{rel_pattern}*{hop}..{hop}]-\"\n",
    "\n",
    "    q = f\"\"\"\n",
    "    MATCH (s)\n",
    "    WHERE id(s) = {seed_id}\n",
    "    MATCH (s){pattern}(n)\n",
    "    WITH DISTINCT n\n",
    "    RETURN count(n) AS frontier_size\n",
    "    \"\"\"\n",
    "    return q\n",
    "\n",
    "def frontier_count_apoc(seed_id, hop, direction=\"OUT\", rel_pattern=\"\"):\n",
    "    \"\"\"\n",
    "    Versión con APOC (apoc.path.expandConfig) para exact hop.\n",
    "    Uniqueness global de nodos para evitar ciclos.\n",
    "    \"\"\"\n",
    "    # APOC usa minLevel/maxLevel; para \"exact hop\" contamos nodos con esa distancia exacta.\n",
    "    # expandConfig con bfs:true y uniqueness:'NODE_GLOBAL' evita revisitar.\n",
    "    dir_map = {\"OUT\":\"OUTGOING\",\"IN\":\"INCOMING\",\"BOTH\":\"BOTH\"}\n",
    "    apoc_dir = dir_map.get(direction.upper(), \"OUTGOING\")\n",
    "\n",
    "    # Tipos de relación\n",
    "    rels = \"\"\n",
    "    if rel_pattern:\n",
    "        # rel_pattern = \":T1|:T2\" -> apoc quiere lista [\"T1\",\"T2\"]\n",
    "        types = [t.replace(\":\", \"\") for t in rel_pattern.split(\"|\")]\n",
    "        rels = f\", relationshipFilter:'{'|'.join(types)}'\"\n",
    "\n",
    "    q = f\"\"\"\n",
    "    MATCH (s) WHERE id(s) = {seed_id}\n",
    "    CALL apoc.path.expandConfig(s, {{\n",
    "        minLevel:{hop}, maxLevel:{hop},\n",
    "        bfs:true, uniqueness:'NODE_GLOBAL',\n",
    "        filterStartNode:true,\n",
    "        {'' if not rels else rels}\n",
    "        direction:'{apoc_dir}'\n",
    "    }}) YIELD path\n",
    "    WITH last(nodes(path)) AS n\n",
    "    RETURN count(DISTINCT n) AS frontier_size\n",
    "    \"\"\"\n",
    "    return q\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EXPERIMENTO\n",
    "# =========================\n",
    "\n",
    "def sample_seeds(n, node_label=None):\n",
    "    return graph.run(seed_query(n, node_label)).to_data_frame()[\"id\"].tolist()\n",
    "\n",
    "def get_out_degree(node_id):\n",
    "    return int(graph.run(out_degree_query(node_id, REL_PATTERN)).to_data_frame()[\"deg\"].iloc[0])\n",
    "\n",
    "def count_frontier(seed_id, hop):\n",
    "    if USE_APOC:\n",
    "        q = frontier_count_apoc(seed_id, hop, DIRECTION, REL_PATTERN)\n",
    "    else:\n",
    "        q = frontier_count_cypher(seed_id, hop, DIRECTION, REL_PATTERN)\n",
    "    df = graph.run(q).to_data_frame()\n",
    "    return int(df[\"frontier_size\"].iloc[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a1819c-30a4-4d26-8003-949d6773e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG EXTRA ===\n",
    "USE_ELEMENT_ID = True  # True: usa elementId(n); False: usa id(n)\n",
    "SEED_PROP = None       # Si prefieres muestrear por una propiedad (ej. 'numeroCuenta'), deja None para aleatorio\n",
    "\n",
    "def seed_query(limit, node_label=None):\n",
    "    ident = \"elementId(n) AS seed_eid\" if USE_ELEMENT_ID else \"id(n) AS seed_id\"\n",
    "    label_part = f\":`{node_label}`\" if node_label else \"\"\n",
    "    if SEED_PROP:\n",
    "        # Muestreo por propiedad existente (ej. numeroCuenta) si quieres controlarlo\n",
    "        return f\"\"\"\n",
    "        MATCH (n{label_part})\n",
    "        WHERE exists(n.`{SEED_PROP}`)\n",
    "        WITH n ORDER BY rand() LIMIT {limit}\n",
    "        RETURN {ident}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        MATCH (n{label_part})\n",
    "        WITH n ORDER BY rand() LIMIT {limit}\n",
    "        RETURN {ident}\n",
    "        \"\"\"\n",
    "\n",
    "def sample_seeds(n, node_label=None):\n",
    "    df = graph.run(seed_query(n, node_label)).to_data_frame()\n",
    "    # Intenta ambas columnas por si acaso\n",
    "    if USE_ELEMENT_ID:\n",
    "        col = \"seed_eid\" if \"seed_eid\" in df.columns else list(df.columns)[0]\n",
    "        return df[col].tolist()\n",
    "    else:\n",
    "        col = \"seed_id\" if \"seed_id\" in df.columns else list(df.columns)[0]\n",
    "        return df[col].tolist()\n",
    "\n",
    "def out_degree_query_eid(seed_eid, rel_pattern):\n",
    "    # OUT-degree usando elementId\n",
    "    if rel_pattern:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)-[r{rel_pattern}]->()\n",
    "        WHERE elementId(n) = '{seed_eid}'\n",
    "        RETURN count(r) AS deg\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)-[r]->()\n",
    "        WHERE elementId(n) = '{seed_eid}'\n",
    "        RETURN count(r) AS deg\n",
    "        \"\"\"\n",
    "\n",
    "def out_degree_query_id(seed_id, rel_pattern):\n",
    "    # OUT-degree usando id()\n",
    "    if rel_pattern:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)-[r{rel_pattern}]->()\n",
    "        WHERE id(n) = {int(seed_id)}\n",
    "        RETURN count(r) AS deg\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        MATCH (n)-[r]->()\n",
    "        WHERE id(n) = {int(seed_id)}\n",
    "        RETURN count(r) AS deg\n",
    "        \"\"\"\n",
    "\n",
    "def get_out_degree(seed_identifier):\n",
    "    if USE_ELEMENT_ID:\n",
    "        q = out_degree_query_eid(seed_identifier, REL_PATTERN)\n",
    "    else:\n",
    "        q = out_degree_query_id(seed_identifier, REL_PATTERN)\n",
    "    return int(graph.run(q).to_data_frame()[\"deg\"].iloc[0])\n",
    "\n",
    "def frontier_count_cypher_eid(seed_eid, hop, direction=\"OUT\", rel_pattern=\"\"):\n",
    "    if direction.upper() == \"OUT\":\n",
    "        pattern = f\"-[r{rel_pattern}*{hop}..{hop}]->\"\n",
    "    elif direction.upper() == \"IN\":\n",
    "        pattern = f\"<-[r{rel_pattern}*{hop}..{hop}]-\"\n",
    "    else:\n",
    "        pattern = f\"-[r{rel_pattern}*{hop}..{hop}]-\"\n",
    "    return f\"\"\"\n",
    "    MATCH (s) WHERE elementId(s) = '{seed_eid}'\n",
    "    MATCH (s){pattern}(n)\n",
    "    WITH DISTINCT n\n",
    "    RETURN count(n) AS frontier_size\n",
    "    \"\"\"\n",
    "\n",
    "def frontier_count_cypher_id(seed_id, hop, direction=\"OUT\", rel_pattern=\"\"):\n",
    "    if direction.upper() == \"OUT\":\n",
    "        pattern = f\"-[r{rel_pattern}*{hop}..{hop}]->\"\n",
    "    elif direction.upper() == \"IN\":\n",
    "        pattern = f\"<-[r{rel_pattern}*{hop}..{hop}]-\"\n",
    "    else:\n",
    "        pattern = f\"-[r{rel_pattern}*{hop}..{hop}]-\"\n",
    "    return f\"\"\"\n",
    "    MATCH (s) WHERE id(s) = {int(seed_id)}\n",
    "    MATCH (s){pattern}(n)\n",
    "    WITH DISTINCT n\n",
    "    RETURN count(n) AS frontier_size\n",
    "    \"\"\"\n",
    "\n",
    "def frontier_count(seed_identifier, hop):\n",
    "    if USE_APOC:\n",
    "        # versión APOC con elementId/id:\n",
    "        dir_map = {\"OUT\":\"OUTGOING\",\"IN\":\"INCOMING\",\"BOTH\":\"BOTH\"}\n",
    "        apoc_dir = dir_map.get(DIRECTION.upper(), \"OUTGOING\")\n",
    "        rels = \"\"\n",
    "        if REL_PATTERN:\n",
    "            types = [t.replace(\":\", \"\") for t in REL_PATTERN.split(\"|\")]\n",
    "            rels = f\", relationshipFilter:'{'|'.join(types)}'\"\n",
    "        if USE_ELEMENT_ID:\n",
    "            q = f\"\"\"\n",
    "            MATCH (s) WHERE elementId(s) = '{seed_identifier}'\n",
    "            CALL apoc.path.expandConfig(s, {{\n",
    "                minLevel:{hop}, maxLevel:{hop},\n",
    "                bfs:true, uniqueness:'NODE_GLOBAL',\n",
    "                filterStartNode:true,\n",
    "                direction:'{apoc_dir}'{rels}\n",
    "            }}) YIELD path\n",
    "            WITH last(nodes(path)) AS n\n",
    "            RETURN count(DISTINCT n) AS frontier_size\n",
    "            \"\"\"\n",
    "        else:\n",
    "            q = f\"\"\"\n",
    "            MATCH (s) WHERE id(s) = {int(seed_identifier)}\n",
    "            CALL apoc.path.expandConfig(s, {{\n",
    "                minLevel:{hop}, maxLevel:{hop},\n",
    "                bfs:true, uniqueness:'NODE_GLOBAL',\n",
    "                filterStartNode:true,\n",
    "                direction:'{apoc_dir}'{rels}\n",
    "            }}) YIELD path\n",
    "            WITH last(nodes(path)) AS n\n",
    "            RETURN count(DISTINCT n) AS frontier_size\n",
    "            \"\"\"\n",
    "        return int(graph.run(q).to_data_frame()[\"frontier_size\"].iloc[0])\n",
    "    else:\n",
    "        # Cypher puro\n",
    "        if USE_ELEMENT_ID:\n",
    "            q = frontier_count_cypher_eid(seed_identifier, hop, DIRECTION, REL_PATTERN)\n",
    "        else:\n",
    "            q = frontier_count_cypher_id(seed_identifier, hop, DIRECTION, REL_PATTERN)\n",
    "        return int(graph.run(q).to_data_frame()[\"frontier_size\"].iloc[0])\n",
    "\n",
    "# Ejemplo de uso (idéntico al bucle anterior):\n",
    "# seeds = sample_seeds(N_SEEDS, NODE_LABEL)\n",
    "# for sid in seeds:\n",
    "#     deg_out = get_out_degree(sid)\n",
    "#     for l in range(1, MAX_HOPS+1):\n",
    "#         frontier_sz = frontier_count(sid, l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ac0398-1e20-4242-b476-c08ab79aba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1/1] Muestreando 1000 semillas…\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(REPEAT_EXPERIMENTS):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Iteración \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mREPEAT_EXPERIMENTS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Muestreando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_SEEDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m semillas…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m \u001b[43msample_seeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_SEEDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNODE_LABEL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sid \u001b[38;5;129;01min\u001b[39;00m tqdm(seeds, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSemillas\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36msample_seeds\u001b[0;34m(n, node_label)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Intenta ambas columnas por si acaso\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_ELEMENT_ID:\n\u001b[0;32m---> 27\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed_eid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed_eid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "all_records = []\n",
    "\n",
    "start = time.time()\n",
    "for rep in range(REPEAT_EXPERIMENTS):\n",
    "    print(f\"[Iteración {rep+1}/{REPEAT_EXPERIMENTS}] Muestreando {N_SEEDS} semillas…\")\n",
    "    seeds = sample_seeds(N_SEEDS, NODE_LABEL)\n",
    "\n",
    "    for sid in tqdm(seeds, desc=\"Semillas\"):\n",
    "        try:\n",
    "            deg_out = get_out_degree(sid)\n",
    "        except Exception as e:\n",
    "            # si algo falla con esta semilla, saltarla\n",
    "            continue\n",
    "\n",
    "        # Recolectar tamaños del frente para hops 1..MAX_HOPS\n",
    "        for l in range(1, MAX_HOPS + 1):\n",
    "            try:\n",
    "                frontier_sz = count_frontier(sid, l)\n",
    "            except Exception as e:\n",
    "                frontier_sz = None\n",
    "\n",
    "            all_records.append({\n",
    "                \"seed_id\": sid,\n",
    "                \"hop\": l,\n",
    "                \"frontier_size\": frontier_sz,\n",
    "                \"deg_out_seed\": deg_out,\n",
    "                \"direction\": DIRECTION\n",
    "            })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Listo. Recolectadas {len(all_records)} filas en {elapsed:.1f}s.\")\n",
    "\n",
    "df = pd.DataFrame(all_records).dropna(subset=[\"frontier_size\"])\n",
    "df.head()\n",
    "print(df.groupby(\"hop\")[\"frontier_size\"].describe())\n",
    "\n",
    "\n",
    "# =========================\n",
    "# AJUSTE DE MODELOS\n",
    "# =========================\n",
    "\n",
    "# --- Modelo A (tu hipótesis):\n",
    "# log N_l = log a + b * l * log(deg_out_seed)\n",
    "# -> y = c0 + c1 * X, donde X = l * log(deg_out_seed)\n",
    "\n",
    "df_A = df.copy()\n",
    "# evitar log(0): reemplaza deg=0 por 1 (o filtra)\n",
    "df_A = df_A[df_A[\"deg_out_seed\"] > 0].copy()\n",
    "df_A[\"X\"] = df_A[\"hop\"] * np.log(df_A[\"deg_out_seed\"])\n",
    "df_A[\"y\"] = np.log(np.clip(df_A[\"frontier_size\"].astype(float), 1.0, None))\n",
    "\n",
    "reg_A = LinearRegression().fit(df_A[[\"X\"]], df_A[\"y\"])\n",
    "c0_A = reg_A.intercept_\n",
    "c1_A = reg_A.coef_[0]\n",
    "\n",
    "# Parámetros interpretables\n",
    "a_hat = math.exp(c0_A)\n",
    "b_hat = c1_A  # porque y = log a + b * l * log deg\n",
    "\n",
    "# R^2\n",
    "r2_A = reg_A.score(df_A[[\"X\"]], df_A[\"y\"])\n",
    "\n",
    "print(\"\\n=== Modelo A (tu hipótesis) ===\")\n",
    "print(f\"log N_l = log a + b * l * log deg_out(seed)\")\n",
    "print(f\"a_hat = {a_hat:.4f}\")\n",
    "print(f\"b_hat = {b_hat:.4f}\")\n",
    "print(f\"R^2   = {r2_A:.4f}\")\n",
    "\n",
    "# --- Modelo B (branching/exponencial, global):\n",
    "# log N_l = log alpha + l * log m\n",
    "# -> y = c0 + c1 * l\n",
    "df_B = df.copy()\n",
    "df_B[\"y\"] = np.log(np.clip(df_B[\"frontier_size\"].astype(float), 1.0, None))\n",
    "df_B[\"l\"] = df_B[\"hop\"].astype(float)\n",
    "\n",
    "reg_B = LinearRegression().fit(df_B[[\"l\"]], df_B[\"y\"])\n",
    "c0_B = reg_B.intercept_\n",
    "c1_B = reg_B.coef_[0]\n",
    "\n",
    "alpha_hat = math.exp(c0_B)\n",
    "m_hat = math.exp(c1_B)\n",
    "r2_B = reg_B.score(df_B[[\"l\"]], df_B[\"y\"])\n",
    "\n",
    "print(\"\\n=== Modelo B (branching/exponencial) ===\")\n",
    "print(f\"log N_l = log alpha + l * log m\")\n",
    "print(f\"alpha_hat = {alpha_hat:.4f}\")\n",
    "print(f\"m_hat     = {m_hat:.4f}  (factor de ramificación promedio por hop)\")\n",
    "print(f\"R^2       = {r2_B:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# VARIANTE DIRIGIDA (estimador size-biased de m)\n",
    "# =========================\n",
    "# Estimar m como el out-degree medio de nodos alcanzados siguiendo una arista saliente \"al azar\"\n",
    "# (size-biased por in-degree). Lo calculamos muestreando M aristas salientes de semillas.\n",
    "\n",
    "M_EDGES_PER_SEED = 5  # ajusta si quieres\n",
    "sampled_out_degs = []\n",
    "\n",
    "print(\"\\nEstimando m (dirigido, size-biased) por muestreo de aristas salientes…\")\n",
    "for sid in tqdm(df[\"seed_id\"].drop_duplicates().tolist()[:N_SEEDS], desc=\"Semillas para m\"):\n",
    "    # vecinos de hop=1\n",
    "    if USE_APOC:\n",
    "        q1 = frontier_count_apoc(sid, 1, DIRECTION, REL_PATTERN).replace(\"RETURN count(DISTINCT n) AS frontier_size\",\n",
    "            \"RETURN collect(DISTINCT id(n)) AS nbrs\")\n",
    "    else:\n",
    "        # Cypher básico para obtener vecinos (no solo el count)\n",
    "        if DIRECTION.upper() == \"OUT\":\n",
    "            pattern = f\"-[r{REL_PATTERN}]->\"\n",
    "        elif DIRECTION.upper() == \"IN\":\n",
    "            pattern = f\"<-[r{REL_PATTERN}]-\"\n",
    "        else:\n",
    "            pattern = f\"-[r{REL_PATTERN}]-\"\n",
    "        q1 = f\"\"\"\n",
    "        MATCH (s) WHERE id(s) = {sid}\n",
    "        MATCH (s){pattern}(n)\n",
    "        RETURN collect(DISTINCT id(n)) AS nbrs\n",
    "        \"\"\"\n",
    "    try:\n",
    "        nbrs = graph.run(q1).to_data_frame()[\"nbrs\"].iloc[0]\n",
    "    except Exception:\n",
    "        continue\n",
    "    if not nbrs:\n",
    "        continue\n",
    "\n",
    "    # muestrear algunos vecinos\n",
    "    take = min(M_EDGES_PER_SEED, len(nbrs))\n",
    "    pick = np.random.choice(nbrs, size=take, replace=False)\n",
    "\n",
    "    # out-degree de esos vecinos (dirigido OUT)\n",
    "    for vid in pick:\n",
    "        try:\n",
    "            deg_v = get_out_degree(int(vid))\n",
    "            sampled_out_degs.append(deg_v)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if len(sampled_out_degs) > 0:\n",
    "    m_size_biased = float(np.mean(sampled_out_degs))\n",
    "    print(f\"m (size-biased, estimado) ≈ {m_size_biased:.4f}\")\n",
    "    # Comparar con m_hat del modelo B\n",
    "    print(f\"Comparación: m_hat (regresión global) = {m_hat:.4f}\")\n",
    "else:\n",
    "    print(\"No se pudo estimar m_size_biased (sin vecinos muestreados).\")\n",
    "\n",
    "# =========================\n",
    "# SALIDA\n",
    "# =========================\n",
    "\n",
    "# Guardar resultados a disco\n",
    "df.to_csv(\"neighbor_explosion_samples.csv\", index=False)\n",
    "print(\"\\nGuardado: neighbor_explosion_samples.csv\")\n",
    "\n",
    "# Un resumen útil por hop\n",
    "summary = df.groupby(\"hop\")[\"frontier_size\"].agg([\"count\",\"mean\",\"median\",\"std\",\"min\",\"max\"]).reset_index()\n",
    "print(\"\\nResumen por hop:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "summary.to_csv(\"neighbor_explosion_summary.csv\", index=False)\n",
    "print(\"Guardado: neighbor_explosion_summary.csv\")\n",
    "\n",
    "print(\"\\nHecho.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d05fc1-2eb4-4292-bfe5-1a710fd2bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
