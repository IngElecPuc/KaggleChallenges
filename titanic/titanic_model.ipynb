{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6234986e-88dd-44bc-b55d-8c3ec1b264e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dp\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from category_encoders import HashingEncoder, TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, RobustScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"This Pipeline instance is not fitted yet.*\",\n",
    "    category=FutureWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda47641-119f-4a62-bdce-444b862540e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E:/Datasets/titanic/wrangled dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732d8d34-38db-480e-89e0-0471b3e95c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w = pd.read_csv(f'{dataset_path}/train.csv')\n",
    "test_w = pd.read_csv(f'{dataset_path}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0d2dcf-6569-4a80-9f30-91e2fc23822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Family', 'Title',\n",
       "       'Deck', 'TicketPrefix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a63ed40-9baf-4432-b2ae-f0b90b9b543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "y = train_w['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b8a66de-aa92-4415-aa72-8a99923be4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d159b5d1-2d9b-4cb5-935f-7fa47a64e26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck</th>\n",
       "      <th>TicketPrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>u</td>\n",
       "      <td>A/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss</td>\n",
       "      <td>u</td>\n",
       "      <td>STON/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>u</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare Embarked  Family Title Deck  \\\n",
       "0       3    0  22.0      1      0   7.2500        S       1    Mr    u   \n",
       "1       1    1  38.0      1      0  71.2833        C       1   Mrs    C   \n",
       "2       3    1  26.0      0      0   7.9250        S       0  Miss    u   \n",
       "3       1    1  35.0      1      0  53.1000        S       1   Mrs    C   \n",
       "4       3    0  35.0      0      0   8.0500        S       0    Mr    u   \n",
       "\n",
       "  TicketPrefix  \n",
       "0           A/  \n",
       "1           PC  \n",
       "2       STON/O  \n",
       "3         NONE  \n",
       "4         NONE  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42877fa-9c51-4c33-b0db-e727b3acfc8b",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74efd9f-ac9b-4424-86f6-4b79f9bf6a22",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286709a9-bed1-4ae9-9a48-201de9cef5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cef45-f88b-45fa-8aa9-68296d153d5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68cb428e-e6a0-4ddc-a1f3-5c8c4bda0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'C' : 1,\n",
    "    'penalty' : 'l2',\n",
    "    'solver' : 'lbfgs',\n",
    "    'l1_ratio' : None,\n",
    "    'class_weight' : None\n",
    "}\n",
    "\n",
    "def logistic_regression_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler()\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=params['C'],\n",
    "        penalty=params['penalty'],\n",
    "        solver=params['solver'],\n",
    "        l1_ratio=params['l1_ratio'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "132ee3ef-b43c-4f98-bb05-39659668bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the search space to avoid inconsistencies\n",
    "param_search_space = [\n",
    "    #Liblinear only supports 'l1' and 'l2' penalties\n",
    "    {\n",
    "        'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "        'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "        'model__C': loguniform(1e-4, 1e4),\n",
    "        'model__penalty': ['l1'],\n",
    "        'model__solver': ['liblinear'],\n",
    "        'model__l1_ratio': uniform(0, 1),\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    }, \n",
    "    {\n",
    "        'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "        'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "        'model__C': loguniform(1e-4, 1e4),\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['liblinear'],\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    },    \n",
    "    #The rest of solvers doesn't support 'l1'\n",
    "    {\n",
    "        'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "        'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "        'model__C': loguniform(1e-4, 1e4),\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'newton-cg', 'newton-cholesky'],\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b87f6e-56b7-4146-934c-955a4785462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['LogisticRegression'] = {}\n",
    "models['LogisticRegression']['pipeline'] = logistic_regression_pipeline\n",
    "models['LogisticRegression']['hyperparams'] = hyperparams\n",
    "models['LogisticRegression']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a825c-a23c-45b8-91e9-9cb0bde1a726",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RidgeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43fb3272-7fcb-4ac9-a185-e04e4dbbe3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'alpha' : 1,\n",
    "    'solver' : 'auto',\n",
    "    'fit_intercept' : True,\n",
    "    'class_weight' : None,\n",
    "}\n",
    "\n",
    "def ridge_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler()\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = RidgeClassifier(\n",
    "        alpha=params['alpha'],\n",
    "        solver=params['solver'],\n",
    "        fit_intercept=params['fit_intercept'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11ebf436-85f0-47f5-9a70-6f955acd17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__alpha': loguniform(1e-4, 1e4), \n",
    "    'model__solver': ['auto', 'lsqr', 'sparse_cg', 'sag'],\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec0a9e-6b06-4b39-948b-30125e28d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['RidgeClassifier'] = {}\n",
    "models['RidgeClassifier']['pipeline'] = ridge_classifier_pipeline\n",
    "models['RidgeClassifier']['hyperparams'] = hyperparams\n",
    "models['RidgeClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ce412-cb5d-48d2-bfe2-2e2a10ab95f5",
   "metadata": {},
   "source": [
    "### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75cab109-b958-4952-b0dd-a4b3fe585a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'C' : 1,\n",
    "    'fit_intercept' : True,\n",
    "    'loss' : 'hinge',\n",
    "    'average' : False,\n",
    "    'class_weight' : None\n",
    "}\n",
    "\n",
    "def passive_aggressive_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler()\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = PassiveAggressiveClassifier(\n",
    "        C=params['C'],\n",
    "        fit_intercept=params['fit_intercept'],\n",
    "        loss=params['loss'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "947690e9-fb92-41d7-922f-6fed47fba056",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__C': loguniform(1e-4, 1e4),\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__loss': ['hinge', 'squared_hinge'],\n",
    "    'model__class_weight': [None, 'balanced'],\n",
    "    'model__average': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "800bcfa4-8076-4c92-8065-cc201543b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['PassiveAggressiveClassifier'] = {}\n",
    "models['PassiveAggressiveClassifier']['pipeline'] = passive_aggressive_classifier_pipeline\n",
    "models['PassiveAggressiveClassifier']['hyperparams'] = hyperparams\n",
    "models['PassiveAggressiveClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81763aa-3ffd-4129-9721-58dd6641cbad",
   "metadata": {},
   "source": [
    "### SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "41bd21f3-8b50-4709-bd3f-d4c34cabdee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "penalty\n",
      "alpha\n",
      "l1_ratio\n",
      "learning_rate\n",
      "eta0\n",
      "power_t\n",
      "tol\n",
      "class_weight\n",
      "average\n"
     ]
    }
   ],
   "source": [
    "for key in param_search_space.keys():\n",
    "    if 'model__' in key:\n",
    "        print(key.replace('model__', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3b0d8243-83b1-43a1-aa35-b9b9340d3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'loss' : 'hinge',\n",
    "    'penalty' : 'l2',\n",
    "    'alpha' : 0.0001,\n",
    "    'l1_ratio' : 0.15,\n",
    "    'learning_rate' : 'optimal',\n",
    "    'eta0' : 0,\n",
    "    'power_t' : 0.5,\n",
    "    'average' : False,\n",
    "    'class_weight' : None,\n",
    "}\n",
    "\n",
    "def sgd_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler()\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = SGDClassifier(\n",
    "        loss=params['loss'],\n",
    "        penalty=params['penalty'],\n",
    "        alpha=params['alpha'],\n",
    "        l1_ratio=params['l1_ratio'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        eta0=params['eta0'],\n",
    "        power_t=params['power_t'],\n",
    "        average=params['average'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a97354d5-a941-4dfc-883a-bd59ea0e4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__loss':            ['hinge', 'log_loss', 'modified_huber', 'squared_hinge'], \n",
    "    'model__penalty':         ['l2', 'l1', 'elasticnet'], \n",
    "    'model__alpha':           loguniform(1e-6, 1e-1), \n",
    "    'model__l1_ratio':        uniform(0.0, 1.0), \n",
    "    'model__learning_rate':   ['optimal', 'invscaling', 'adaptive'], \n",
    "    'model__eta0':            loguniform(1e-4, 1e-1), \n",
    "    'model__power_t':         uniform(0.1, 0.9), \n",
    "    'model__class_weight':    [None, 'balanced'], \n",
    "    'model__average':         [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "45d5ecc2-075a-428e-8226-5019505d0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['SGDClassifier'] = {}\n",
    "models['SGDClassifier']['pipeline'] = sgd_classifier_pipeline\n",
    "models['SGDClassifier']['hyperparams'] = hyperparams\n",
    "models['SGDClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b6fd947f-71a7-4d66-9140-12cd1b87c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best hyperparameters for SGDClassifier:\n",
      "{'model__alpha': np.float64(0.01316670892247693), 'model__average': False, 'model__class_weight': 'balanced', 'model__eta0': np.float64(0.05865221789706591), 'model__l1_ratio': np.float64(0.6280679266629924), 'model__learning_rate': 'adaptive', 'model__loss': 'log_loss', 'model__penalty': 'l2', 'model__power_t': np.float64(0.24572408959550807), 'preproc__hash__hasher__n_features': 43, 'preproc__robust__quantile_range': (1.0, 99.0)}\n",
      "Best accuracy for SGDClassifier: 0.813\n"
     ]
    }
   ],
   "source": [
    "HyperparameterSearch('SGDClassifier', sgd_classifier_pipeline(hyperparams), param_search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa373bc-2f0b-49e7-8c72-08f3202927d2",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f556f2d-fca6-4284-8f47-46f87e4cd5a4",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2fcf4-152f-41cb-b333-5bbd1ca9a78a",
   "metadata": {},
   "source": [
    "## Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc64c6e-73f3-4935-803d-5649076052e0",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ae53c-5d36-423e-9bb0-17763aa7e5bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d15f8-b84c-4029-975d-a154b33b76a7",
   "metadata": {},
   "source": [
    "This model is not affected too much by scaling, so I am going to leave untouch the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4642633-a89b-4356-bf0f-bb63f1c699e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'n_estimators' : 100,\n",
    "    'criterion' : 'gini',\n",
    "    'max_depth' : None,\n",
    "    'min_samples_split' : 2,\n",
    "    'min_samples_leaf' : 5,\n",
    "    'max_features' : 'sqrt',\n",
    "    'bootstrap' : True,\n",
    "    'n_jobs' : None\n",
    "}\n",
    "\n",
    "def random_forest_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') #Replaces Hashing encoder\n",
    "    #hashing_tf = HashingEncoder(n_components=params['n_components'], cols=hash_cols)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        criterion=params['criterion'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_split=params['min_samples_split'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'], \n",
    "        bootstrap=params['bootstrap'], \n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08a7f364-91f2-4e34-92c3-ee1355609771",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__n_estimators': randint(100, 501),\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [None] + list(range(5, 51, 5)),\n",
    "    'model__min_samples_split': randint(2, 21),\n",
    "    'model__min_samples_leaf': randint(1, 11),\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5],\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'model__ccp_alpha': uniform(0.0, 0.01)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee593c8a-b1b8-4193-8f5b-70ddcb2c982a",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4d839-c3bb-4f9e-be4e-78076bfc749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c65a8bc-3926-485f-ac15-02a0c44ccf75",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42e1311-356e-4fd5-867e-bde70a38e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "#X_test = test_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y = train_w['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a98a8-c4ad-4ae7-850c-d3e1a4109ab3",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d922c3-067f-467a-a59d-c31eeccbc087",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eed326-73e7-4044-aaaf-f4b3ea586aea",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b779d1b-846a-4775-a736-1409ae61fc50",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcd043-f75f-4c72-bc1c-aaced22e1527",
   "metadata": {},
   "source": [
    "### GaussianNB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d019e-8580-4f81-b416-2436a71129c4",
   "metadata": {},
   "source": [
    "### CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a914c-cfc0-4b89-85a5-ded5814a7a2f",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a21456-b1a3-4fb1-bb71-79b2b94416e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa10de2e-2ecc-421e-bd42-8633fd1f8bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Mejores parámetros:\n",
      " {'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100, 'preproc__hash__hasher__n_features': 16}\n",
      "Mejor accuracy en CV: 0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0a71b2-6e5d-4d1d-98af-69188353fd97",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e3715f3-f092-4023-98b3-bed4dcc2a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperparameterSearch(name, pipeline, param_distributions):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=107)\n",
    "    \n",
    "    rand_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        error_score='raise',\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=100,               \n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        random_state=107,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rand_search.fit(X, y)\n",
    "    \n",
    "    print(f'Best hyperparameters for {name}:\\n{rand_search.best_params_}')\n",
    "    print(f'Best accuracy for {name}: {rand_search.best_score_:.3f}')\n",
    "    \n",
    "    best_hyperparams = hyperparams.copy()\n",
    "    for hyperparam, value in rand_search.best_params_.items():\n",
    "        if 'model__' in hyperparam:\n",
    "            best_hyperparams[hyperparam.replace('model__', '')] = value\n",
    "        elif 'preproc__' in hyperparam:\n",
    "            best_hyperparams['n_features'] = value\n",
    "    \n",
    "    best_model = rand_search.best_estimator_\n",
    "    y_pred = best_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2991c18-edd8-42d9-b105-2db46ffa625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "solver='cholesky' does not support fitting the intercept on sparse data. Please set the solver to 'auto' or 'lsqr', 'sparse_cg', 'sag', 'lbfgs' or set `fit_intercept=False`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1571, in fit\n    super().fit(X, Y, sample_weight=sample_weight)\n  File \"E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 930, in fit\n    raise ValueError(\nValueError: solver='cholesky' does not support fitting the intercept on sparse data. Please set the solver to 'auto' or 'lsqr', 'sparse_cg', 'sag', 'lbfgs' or set `fit_intercept=False`\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mHyperparameterSearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRidgeClassifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mridge_classifier_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_search_space\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[88], line 16\u001b[0m, in \u001b[0;36mHyperparameterSearch\u001b[1;34m(name, pipeline, param_distributions)\u001b[0m\n\u001b[0;32m      2\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m107\u001b[39m)\n\u001b[0;32m      4\u001b[0m rand_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m      5\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[0;32m      6\u001b[0m     error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[43mrand_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest hyperparameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrand_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrand_search\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: solver='cholesky' does not support fitting the intercept on sparse data. Please set the solver to 'auto' or 'lsqr', 'sparse_cg', 'sag', 'lbfgs' or set `fit_intercept=False`"
     ]
    }
   ],
   "source": [
    "HyperparameterSearch('RidgeClassifier', ridge_classifier_pipeline(hyperparams), param_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be43a73-c7a0-47f6-8318-f6d5181ac5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_test)\n",
    "y_pred = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276ea5e-a3ff-4a21-af54-5266d0b9705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy en test: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cec5bef-e24f-4cc7-8343-e785620d8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CV por pliegue: [0.75977654 0.79775281 0.79775281 0.7247191  0.82022472]\n",
      "Media de accuracy CV: 0.7800 ± 0.0338\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    estimator=pipe,         # tu pipeline (sin grid search)\n",
    "    X=X, \n",
    "    y=y,\n",
    "    cv=5,                   # número de pliegues\n",
    "    scoring='accuracy',     # métrica\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Accuracy CV por pliegue:\", scores)\n",
    "print(\"Media de accuracy CV: {:.4f} ± {:.4f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458751b3-e018-496b-874f-9117eae2fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=107,\n",
    "                                                    stratify=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
