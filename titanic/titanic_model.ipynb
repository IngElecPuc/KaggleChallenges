{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6234986e-88dd-44bc-b55d-8c3ec1b264e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from category_encoders import HashingEncoder, TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, RobustScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"This Pipeline instance is not fitted yet.*\",\n",
    "    category=FutureWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda47641-119f-4a62-bdce-444b862540e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E:/Datasets/titanic/wrangled dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732d8d34-38db-480e-89e0-0471b3e95c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w = pd.read_csv(f'{dataset_path}/train.csv')\n",
    "test_w = pd.read_csv(f'{dataset_path}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0d2dcf-6569-4a80-9f30-91e2fc23822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Family', 'Title',\n",
      "       'Deck', 'TicketPrefix'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_w.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a63ed40-9baf-4432-b2ae-f0b90b9b543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "#X_test = test_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y = train_w['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8a66de-aa92-4415-aa72-8a99923be4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d159b5d1-2d9b-4cb5-935f-7fa47a64e26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck</th>\n",
       "      <th>TicketPrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>u</td>\n",
       "      <td>A/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss</td>\n",
       "      <td>u</td>\n",
       "      <td>STON/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>u</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare Embarked  Family Title Deck  \\\n",
       "0       3    0  22.0      1      0   7.2500        S       1    Mr    u   \n",
       "1       1    1  38.0      1      0  71.2833        C       1   Mrs    C   \n",
       "2       3    1  26.0      0      0   7.9250        S       0  Miss    u   \n",
       "3       1    1  35.0      1      0  53.1000        S       1   Mrs    C   \n",
       "4       3    0  35.0      0      0   8.0500        S       0    Mr    u   \n",
       "\n",
       "  TicketPrefix  \n",
       "0           A/  \n",
       "1           PC  \n",
       "2       STON/O  \n",
       "3         NONE  \n",
       "4         NONE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42877fa-9c51-4c33-b0db-e727b3acfc8b",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74efd9f-ac9b-4424-86f6-4b79f9bf6a22",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cef45-f88b-45fa-8aa9-68296d153d5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cb428e-e6a0-4ddc-a1f3-5c8c4bda0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'quantile_range': (25.0, 75.0),\n",
    "    'C' : 1,\n",
    "    'penalty' : 'l2',\n",
    "    'solver' : 'lbfgs',\n",
    "    'l1_ratio' : None,\n",
    "    'class_weight' : None\n",
    "}\n",
    "\n",
    "def logistic_regression_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler(quantile_range=params['quantile_range'])\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=params['C'],\n",
    "        penalty=params['penalty'],\n",
    "        solver=params['solver'],\n",
    "        l1_ratio=params['l1_ratio'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132ee3ef-b43c-4f98-bb05-39659668bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the search space to avoid inconsistencies\n",
    "param_search_space = [\n",
    "    #Liblinear only supports 'l1' and 'l2' penalties\n",
    "    {\n",
    "        'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "        'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "        'model__C': loguniform(1e-4, 1e4),\n",
    "        'model__penalty': ['l1'],\n",
    "        'model__solver': ['liblinear'],\n",
    "        'model__l1_ratio': uniform(0, 1),\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    }, \n",
    "    {\n",
    "        'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "        'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "        'model__C': loguniform(1e-4, 1e4),\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['liblinear'],\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    },    \n",
    "    #The rest of solvers doesn't support 'l1'\n",
    "    {\n",
    "        'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "        'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "        'model__C': loguniform(1e-4, 1e4),\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'newton-cg', 'newton-cholesky'],\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b87f6e-56b7-4146-934c-955a4785462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['LogisticRegression'] = {}\n",
    "models['LogisticRegression']['pipeline'] = logistic_regression_pipeline\n",
    "models['LogisticRegression']['hyperparams'] = hyperparams\n",
    "models['LogisticRegression']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a825c-a23c-45b8-91e9-9cb0bde1a726",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RidgeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fb3272-7fcb-4ac9-a185-e04e4dbbe3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'quantile_range': (25.0, 75.0),\n",
    "    'alpha' : 1,\n",
    "    'solver' : 'auto',\n",
    "    'fit_intercept' : True,\n",
    "    'class_weight' : None,\n",
    "}\n",
    "\n",
    "def ridge_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler(quantile_range=params['quantile_range'])\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = RidgeClassifier(\n",
    "        alpha=params['alpha'],\n",
    "        solver=params['solver'],\n",
    "        fit_intercept=params['fit_intercept'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ebf436-85f0-47f5-9a70-6f955acd17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__alpha': loguniform(1e-4, 1e4), \n",
    "    'model__solver': ['auto', 'lsqr', 'sparse_cg', 'sag'],\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ec0a9e-6b06-4b39-948b-30125e28d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['RidgeClassifier'] = {}\n",
    "models['RidgeClassifier']['pipeline'] = ridge_classifier_pipeline\n",
    "models['RidgeClassifier']['hyperparams'] = hyperparams\n",
    "models['RidgeClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ce412-cb5d-48d2-bfe2-2e2a10ab95f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75cab109-b958-4952-b0dd-a4b3fe585a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'quantile_range': (25.0, 75.0),\n",
    "    'C' : 1,\n",
    "    'fit_intercept' : True,\n",
    "    'loss' : 'hinge',\n",
    "    'average' : False,\n",
    "    'class_weight' : None\n",
    "}\n",
    "\n",
    "def passive_aggressive_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler(quantile_range=params['quantile_range'])\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = PassiveAggressiveClassifier(\n",
    "        C=params['C'],\n",
    "        fit_intercept=params['fit_intercept'],\n",
    "        loss=params['loss'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "947690e9-fb92-41d7-922f-6fed47fba056",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__C': loguniform(1e-4, 1e4),\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__loss': ['hinge', 'squared_hinge'],\n",
    "    'model__class_weight': [None, 'balanced'],\n",
    "    'model__average': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "800bcfa4-8076-4c92-8065-cc201543b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['PassiveAggressiveClassifier'] = {}\n",
    "models['PassiveAggressiveClassifier']['pipeline'] = passive_aggressive_classifier_pipeline\n",
    "models['PassiveAggressiveClassifier']['hyperparams'] = hyperparams\n",
    "models['PassiveAggressiveClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81763aa-3ffd-4129-9721-58dd6641cbad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b0d8243-83b1-43a1-aa35-b9b9340d3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'quantile_range': (25.0, 75.0),\n",
    "    'loss' : 'hinge',\n",
    "    'penalty' : 'l2',\n",
    "    'alpha' : 0.0001,\n",
    "    'l1_ratio' : 0.15,\n",
    "    'learning_rate' : 'optimal',\n",
    "    'eta0' : 0,\n",
    "    'power_t' : 0.5,\n",
    "    'average' : False,\n",
    "    'class_weight' : None,\n",
    "}\n",
    "\n",
    "def sgd_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler(quantile_range=params['quantile_range'])\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = SGDClassifier(\n",
    "        loss=params['loss'],\n",
    "        penalty=params['penalty'],\n",
    "        alpha=params['alpha'],\n",
    "        l1_ratio=params['l1_ratio'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        eta0=params['eta0'],\n",
    "        power_t=params['power_t'],\n",
    "        average=params['average'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=107 \n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97354d5-a941-4dfc-883a-bd59ea0e4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__loss':            ['hinge', 'log_loss', 'modified_huber', 'squared_hinge'], \n",
    "    'model__penalty':         ['l2', 'l1', 'elasticnet'], \n",
    "    'model__alpha':           loguniform(1e-6, 1e-1), \n",
    "    'model__l1_ratio':        uniform(0.0, 1.0), \n",
    "    'model__learning_rate':   ['optimal', 'invscaling', 'adaptive'], \n",
    "    'model__eta0':            loguniform(1e-4, 1e-1), \n",
    "    'model__power_t':         uniform(0.1, 0.9), \n",
    "    'model__class_weight':    [None, 'balanced'], \n",
    "    'model__average':         [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45d5ecc2-075a-428e-8226-5019505d0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['SGDClassifier'] = {}\n",
    "models['SGDClassifier']['pipeline'] = sgd_classifier_pipeline\n",
    "models['SGDClassifier']['hyperparams'] = hyperparams\n",
    "models['SGDClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa373bc-2f0b-49e7-8c72-08f3202927d2",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f556f2d-fca6-4284-8f47-46f87e4cd5a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "369e7acd-555c-4160-98c3-6cd5e472b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'quantile_range': (25.0, 75.0),\n",
    "    'n_neighbors' : 5,\n",
    "    'weights' : 'uniform',\n",
    "    'p' : 2,\n",
    "    'leaf_size' : 30,\n",
    "}\n",
    "\n",
    "def knn_classifier_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    rb_tf = RobustScaler(quantile_range=params['quantile_range'])\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=params['n_neighbors'],\n",
    "        weights=params['weights'],\n",
    "        p=params['p'],\n",
    "        leaf_size=params['leaf_size']\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8febe34-40e6-4a42-b13d-60f06c938cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__n_neighbors': randint(3, 51),\n",
    "    'model__weights': ['uniform', 'distance'], \n",
    "    'model__p': [1, 2], \n",
    "    'model__leaf_size': randint(10, 61), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "690607fd-10f8-412f-a36f-7079951e6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['KNeighborsClassifier'] = {}\n",
    "models['KNeighborsClassifier']['pipeline'] = knn_classifier_pipeline\n",
    "models['KNeighborsClassifier']['hyperparams'] = hyperparams\n",
    "models['KNeighborsClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2fcf4-152f-41cb-b333-5bbd1ca9a78a",
   "metadata": {},
   "source": [
    "## Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc64c6e-73f3-4935-803d-5649076052e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e20fd123-2f64-4ed9-b89e-2caa61193f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'criterion' : 'gini',\n",
    "    'max_depth' : None,\n",
    "    'min_samples_split' : 2,\n",
    "    'min_samples_leaf' : 1,\n",
    "    'max_features' : None,\n",
    "    'class_weight' : None,\n",
    "    'ccp_alpha' : 0\n",
    "}\n",
    "\n",
    "def decision_tree_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') #Replaces Hashing encoder\n",
    "    #hashing_tf = HashingEncoder(n_components=params['n_components'], cols=hash_cols)\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=params['criterion'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_split=params['min_samples_split'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'], \n",
    "        class_weight=params['class_weight'],\n",
    "        ccp_alpha=params['ccp_alpha'],\n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd25481e-5a89-4298-b52e-382303977a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'model__max_depth': [None] + list(range(1, 21)),\n",
    "    'model__min_samples_split': randint(2, 21),\n",
    "    'model__min_samples_leaf': randint(1, 21),\n",
    "    'model__max_features': [None, 'sqrt', 'log2'],\n",
    "    'model__class_weight': [None, 'balanced'],\n",
    "    'model__ccp_alpha': loguniform(1e-4, 1e-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c83202-fdc6-464a-95ce-e80771ee6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['DecisionTreeClassifier'] = {}\n",
    "models['DecisionTreeClassifier']['pipeline'] = decision_tree_pipeline\n",
    "models['DecisionTreeClassifier']['hyperparams'] = hyperparams\n",
    "models['DecisionTreeClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ae53c-5d36-423e-9bb0-17763aa7e5bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d15f8-b84c-4029-975d-a154b33b76a7",
   "metadata": {},
   "source": [
    "This model is not affected too much by scaling, so I am going to leave untouch the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4642633-a89b-4356-bf0f-bb63f1c699e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'n_estimators' : 100,\n",
    "    'criterion' : 'gini',\n",
    "    'max_depth' : None,\n",
    "    'min_samples_split' : 2,\n",
    "    'min_samples_leaf' : 5,\n",
    "    'max_features' : 'sqrt',\n",
    "    'bootstrap' : True,\n",
    "    'class_weight' : None,\n",
    "    'ccp_alpha' : 0\n",
    "}\n",
    "\n",
    "def random_forest_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') #Replaces Hashing encoder\n",
    "    #hashing_tf = HashingEncoder(n_components=params['n_components'], cols=hash_cols)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        criterion=params['criterion'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_split=params['min_samples_split'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'], \n",
    "        bootstrap=params['bootstrap'], \n",
    "        class_weight=params['class_weight'],\n",
    "        ccp_alpha=params['ccp_alpha'],\n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08a7f364-91f2-4e34-92c3-ee1355609771",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__n_estimators': randint(100, 501),\n",
    "    'model__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'model__max_depth': [None] + list(range(5, 51, 5)),\n",
    "    'model__min_samples_split': randint(2, 21),\n",
    "    'model__min_samples_leaf': randint(1, 11),\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5],\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'model__ccp_alpha': uniform(0.0, 0.01)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94caabaf-7974-4875-af99-9ff4007e2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['RandomForestClassifier'] = {}\n",
    "models['RandomForestClassifier']['pipeline'] = random_forest_pipeline\n",
    "models['RandomForestClassifier']['hyperparams'] = hyperparams\n",
    "models['RandomForestClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee593c8a-b1b8-4193-8f5b-70ddcb2c982a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7cb2cd2-50d9-431b-9de4-86878b96d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'n_estimators' : 100,\n",
    "    'criterion' : 'gini',\n",
    "    'max_depth' : None,\n",
    "    'min_samples_split' : 2,\n",
    "    'min_samples_leaf' : 5,\n",
    "    'max_features' : 'sqrt',\n",
    "    'bootstrap' : False,\n",
    "    'class_weight' : None,\n",
    "    'ccp_alpha' : 0\n",
    "}\n",
    "\n",
    "def extra_trees_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') #Replaces Hashing encoder\n",
    "    #hashing_tf = HashingEncoder(n_components=params['n_components'], cols=hash_cols)\n",
    "    \n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        criterion=params['criterion'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_split=params['min_samples_split'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'], \n",
    "        bootstrap=params['bootstrap'], \n",
    "        class_weight=params['class_weight'],\n",
    "        ccp_alpha=params['ccp_alpha'],\n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8f2ccff-59d3-4038-80a4-e4dd9e5a2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__n_estimators': randint(100, 501),\n",
    "    'model__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'model__max_depth': [None] + list(range(1, 31)),\n",
    "    'model__min_samples_split': randint(2, 21),\n",
    "    'model__min_samples_leaf': randint(1, 21),\n",
    "    'model__max_features': ['sqrt', 'log2', 0.2, 0.5],\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'model__ccp_alpha': uniform(0.0, 0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "762040a3-2692-4f68-84bd-5be06226b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['ExtraTreesClassifier'] = {}\n",
    "models['ExtraTreesClassifier']['pipeline'] = extra_trees_pipeline\n",
    "models['ExtraTreesClassifier']['hyperparams'] = hyperparams\n",
    "models['ExtraTreesClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65a8bc-3926-485f-ac15-02a0c44ccf75",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a98a8-c4ad-4ae7-850c-d3e1a4109ab3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7598a2cc-ffd8-4103-9c75-10251fcf049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'loss': 'log_loss',\n",
    "    'criterion' : 'gini',\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators' : 100,\n",
    "    'subsample' : 1,\n",
    "    'max_depth' : None,\n",
    "    'min_samples_split' : 2,\n",
    "    'min_samples_leaf' : 5,\n",
    "    'max_features' : 'sqrt'\n",
    "}\n",
    "\n",
    "def gradient_boosting_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') #Replaces Hashing encoder\n",
    "    #hashing_tf = HashingEncoder(n_components=params['n_components'], cols=hash_cols)\n",
    "    \n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        loss=params['loss'], \n",
    "        criterion=params['criterion'], \n",
    "        learning_rate=params['learning_rate'], \n",
    "        subsample=params['subsample'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_split=params['min_samples_split'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'],\n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "701a8f80-9af3-4f82-b3cd-29fde186ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__loss': ['log_loss', 'exponential'],\n",
    "    'model__criterion': ['friedman_mse', 'squared_error'],\n",
    "    'model__learning_rate': loguniform(1e-3, 1e-1),\n",
    "    'model__n_estimators': randint(100, 1000),\n",
    "    'model__subsample': uniform(0.5, 0.5),\n",
    "    'model__max_depth': [None] + list(range(3, 11)),\n",
    "    'model__min_samples_split': randint(2, 20),\n",
    "    'model__min_samples_leaf': randint(1, 20),\n",
    "    'model__max_features': ['sqrt', 'log2', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28870a40-46da-411c-a182-7a04cfac58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['GradientBoostingClassifier'] = {}\n",
    "models['GradientBoostingClassifier']['pipeline'] = gradient_boosting_pipeline\n",
    "models['GradientBoostingClassifier']['hyperparams'] = hyperparams\n",
    "models['GradientBoostingClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d922c3-067f-467a-a59d-c31eeccbc087",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77401320-f020-4357-ae4d-c54681a81d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate\n",
      "l2_regularization\n",
      "max_iter\n",
      "max_leaf_nodes\n",
      "max_depth\n",
      "min_samples_split\n",
      "min_samples_leaf\n",
      "max_features\n"
     ]
    }
   ],
   "source": [
    "for key in param_search_space.keys():\n",
    "    if 'model__' in key:\n",
    "        print(key.replace('model__', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe1017ca-8c80-4308-95f1-dc2a5e861ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'learning_rate': 1,\n",
    "    'l2_regularization' : 0,\n",
    "    'max_iter' : 100,\n",
    "    'max_depth' : None,\n",
    "    'min_samples_leaf' : 20,\n",
    "    'max_features' : 1\n",
    "}\n",
    "\n",
    "def hist_gradient_boosting_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "\n",
    "    def to_dense(X): # FeatureHasher gets sparse matrices by default\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False) #This avoids sparce matrices when encoding\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') \n",
    "    \n",
    "    model = HistGradientBoostingClassifier(\n",
    "        learning_rate=params['learning_rate'], \n",
    "        l2_regularization=params['l2_regularization'], \n",
    "        max_iter=params['max_iter'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'],\n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([\n",
    "            ('to_dict', dict_tf), \n",
    "            ('hasher', hasher), \n",
    "            ('dense', FunctionTransformer(to_dense, validate=False))  \n",
    "        ]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67ac2aa8-800c-489d-8803-51a6c23d1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__learning_rate': loguniform(1e-3, 1e-1),\n",
    "    'model__l2_regularization' : loguniform(1e-4, 1e1),\n",
    "    'model__max_iter' : randint(100, 1000),\n",
    "    'model__max_leaf_nodes' : randint(10, 100),\n",
    "    'model__max_depth': [None] + list(range(3, 11)),\n",
    "    'model__min_samples_leaf': randint(1, 20),\n",
    "    'model__max_features' : uniform(0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7af271f0-59b8-48ac-8731-5568db577271",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['HistGradientBoostingClassifier'] = {}\n",
    "models['HistGradientBoostingClassifier']['pipeline'] = hist_gradient_boosting_pipeline\n",
    "models['HistGradientBoostingClassifier']['hyperparams'] = hyperparams\n",
    "models['HistGradientBoostingClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eed326-73e7-4044-aaaf-f4b3ea586aea",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23a5c6c5-f7bf-4bc7-8ab8-ca126eef0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate\n",
      "n_estimators\n",
      "max_depth\n",
      "subsample\n",
      "colsample_bytree\n",
      "gamma\n",
      "reg_alpha\n",
      "reg_lambda\n"
     ]
    }
   ],
   "source": [
    "for key in param_search_space.keys():\n",
    "    if 'model__' in key:\n",
    "        print(key.replace('model__', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11485d49-505e-45a5-8198-7a5d90c2cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.3,\n",
    "    'subsample': 1.0, \n",
    "    'colsample_bytree': 1.0, \n",
    "    'max_depth': 6, \n",
    "    'gamma': 0.0, \n",
    "    'reg_alpha': 0.0, \n",
    "    'reg_lambda': 1.0 \n",
    "}\n",
    "\n",
    "def xgb_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "\n",
    "    def to_dense(X): # FeatureHasher gets sparse matrices by default\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False) #This avoids sparce matrices when encoding\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') \n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        learning_rate=params['learning_rate'], \n",
    "        subsample=params['subsample'], \n",
    "        colsample_bytree=params['colsample_bytree'], \n",
    "        max_depth=params['max_depth'], \n",
    "        gamma=params['gamma'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([\n",
    "            ('to_dict', dict_tf), \n",
    "            ('hasher', hasher), \n",
    "            ('dense', FunctionTransformer(to_dense, validate=False))  \n",
    "        ]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5abb72ec-d6f1-49c8-a460-5a8aace99ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__learning_rate': loguniform(1e-3, 0.3),\n",
    "    'model__n_estimators' : randint(100, 1000),\n",
    "    'model__max_depth': [None] + list(range(3, 10)),\n",
    "    'model__subsample' : uniform(0.5, 0.5),  # rango [0.5, 1.0]\n",
    "    'model__colsample_bytree' : uniform(0.5, 0.5),  # rango [0.5, 1.0]\n",
    "    'model__gamma' : loguniform(1e-8, 1.0),\n",
    "    'model__reg_alpha' : loguniform(1e-8, 10.0),\n",
    "    'model__reg_lambda' : loguniform(1e-8, 10.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f19e1e52-5da2-4872-9ffb-a7ebbb10b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['XGBClassifier'] = {}\n",
    "models['XGBClassifier']['pipeline'] = xgb_pipeline\n",
    "models['XGBClassifier']['hyperparams'] = hyperparams\n",
    "models['XGBClassifier']['param_search'] = param_search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e9648bf-87de-405b-a39c-ac9fb99b9139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best hyperparameters for AdaBoostClassifier:\n",
      "{'model__colsample_bytree': np.float64(0.5495495291817685), 'model__gamma': np.float64(4.047437410073303e-06), 'model__learning_rate': np.float64(0.011945438548210922), 'model__max_depth': 6, 'model__n_estimators': 335, 'model__reg_alpha': np.float64(7.941540593151457e-06), 'model__reg_lambda': np.float64(8.143033028453104e-06), 'model__subsample': np.float64(0.6397238015550946), 'preproc__hash__hasher__n_features': 51}\n",
      "Best accuracy for AdaBoostClassifier: 0.842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=107, shuffle=True),\n",
       "                   error_score=&#x27;raise&#x27;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preproc&#x27;,\n",
       "                                              ColumnTransformer(transformers=[(&#x27;hash&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;to_dict&#x27;,\n",
       "                                                                                                FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.df_to_dicts at 0x000001D55188D480&gt;)),\n",
       "                                                                                               (&#x27;hasher&#x27;,\n",
       "                                                                                                FeatureHasher(n_features=8)),\n",
       "                                                                                               (&#x27;dense...\n",
       "                                        &#x27;model__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D551C54700&gt;,\n",
       "                                        &#x27;model__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D551C54B80&gt;,\n",
       "                                        &#x27;preproc__hash__hasher__n_features&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001D551C57790&gt;},\n",
       "                   random_state=107, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=107, shuffle=True),\n",
       "                   error_score=&#x27;raise&#x27;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preproc&#x27;,\n",
       "                                              ColumnTransformer(transformers=[(&#x27;hash&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;to_dict&#x27;,\n",
       "                                                                                                FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.df_to_dicts at 0x000001D55188D480&gt;)),\n",
       "                                                                                               (&#x27;hasher&#x27;,\n",
       "                                                                                                FeatureHasher(n_features=8)),\n",
       "                                                                                               (&#x27;dense...\n",
       "                                        &#x27;model__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D551C54700&gt;,\n",
       "                                        &#x27;model__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D551C54B80&gt;,\n",
       "                                        &#x27;preproc__hash__hasher__n_features&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001D551C57790&gt;},\n",
       "                   random_state=107, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preproc&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;hash&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;to_dict&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.df_to_dicts at 0x000001D55188D480&gt;)),\n",
       "                                                                  (&#x27;hasher&#x27;,\n",
       "                                                                   FeatureHasher(n_features=51)),\n",
       "                                                                  (&#x27;dense&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.to_dense at 0x000001D551BC7010&gt;))]),\n",
       "                                                  [&#x27;Title&#x27;...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=np.float64(0.011945438548210922),\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=335, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preproc: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preproc: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;hash&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;to_dict&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.df_to_dicts at 0x000001D55188D480&gt;)),\n",
       "                                                 (&#x27;hasher&#x27;,\n",
       "                                                  FeatureHasher(n_features=51)),\n",
       "                                                 (&#x27;dense&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.to_dense at 0x000001D551BC7010&gt;))]),\n",
       "                                 [&#x27;Title&#x27;, &#x27;Deck&#x27;, &#x27;TicketPrefix&#x27;]),\n",
       "                                (&#x27;ohe&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Embarked&#x27;]),\n",
       "                                (&#x27;num_passthrough&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001D551D93AF0&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>hash</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Title&#x27;, &#x27;Deck&#x27;, &#x27;TicketPrefix&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>df_to_dicts</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.df_to_dicts at 0x000001D55188D480&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>FeatureHasher</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.FeatureHasher.html\">?<span>Documentation for FeatureHasher</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FeatureHasher(n_features=51)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>to_dense</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function ada_boosting_pipeline.&lt;locals&gt;.to_dense at 0x000001D551BC7010&gt;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ohe</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Embarked&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num_passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001D551D93AF0&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=np.float64(0.5495495291817685), device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=np.float64(4.047437410073303e-06), grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=np.float64(0.011945438548210922), max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=335, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=107, shuffle=True),\n",
       "                   error_score='raise',\n",
       "                   estimator=Pipeline(steps=[('preproc',\n",
       "                                              ColumnTransformer(transformers=[('hash',\n",
       "                                                                               Pipeline(steps=[('to_dict',\n",
       "                                                                                                FunctionTransformer(func=<function ada_boosting_pipeline.<locals>.df_to_dicts at 0x000001D55188D480>)),\n",
       "                                                                                               ('hasher',\n",
       "                                                                                                FeatureHasher(n_features=8)),\n",
       "                                                                                               ('dense...\n",
       "                                        'model__reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D551C54700>,\n",
       "                                        'model__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D551C54B80>,\n",
       "                                        'preproc__hash__hasher__n_features': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001D551C57790>},\n",
       "                   random_state=107, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HyperparameterSearch('XGBClassifier', xgb_pipeline(hyperparams), param_search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b779d1b-846a-4775-a736-1409ae61fc50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcd043-f75f-4c72-bc1c-aaced22e1527",
   "metadata": {},
   "source": [
    "### GaussianNB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d019e-8580-4f81-b416-2436a71129c4",
   "metadata": {},
   "source": [
    "### CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a914c-cfc0-4b89-85a5-ded5814a7a2f",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a21456-b1a3-4fb1-bb71-79b2b94416e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10de2e-2ecc-421e-bd42-8633fd1f8bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0a71b2-6e5d-4d1d-98af-69188353fd97",
   "metadata": {},
   "source": [
    "# Hyperparameter search and benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0899f9d9-ad51-4bd2-b9b0-adfd1cd9ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperparameterSearch(name, pipeline, param_distributions, verbose=True):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=107)\n",
    "    \n",
    "    rand_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        error_score='raise',\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=100,               \n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        random_state=107,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rand_search.fit(X, y)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Best hyperparameters for {name}:\\n{rand_search.best_params_}')\n",
    "        print(f'Best accuracy for {name}: {rand_search.best_score_:.3f}')\n",
    "    \n",
    "    return rand_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2991c18-edd8-42d9-b105-2db46ffa625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "+-----------------------------+---------------+----------+\n",
      "|            Model            | Training time | Accuracy |\n",
      "+-----------------------------+---------------+----------+\n",
      "|      LogisticRegression     |   6.9080 [s]  |  0.8373  |\n",
      "|       RidgeClassifier       |  10.3780 [s]  |  0.8361  |\n",
      "| PassiveAggressiveClassifier |   5.2185 [s]  |  0.8025  |\n",
      "|        SGDClassifier        |   5.9230 [s]  |  0.8227  |\n",
      "+-----------------------------+---------------+----------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'Training time', 'Accuracy']\n",
    "\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    pipeline = models[model]['pipeline']\n",
    "    hyperparams = models[model]['hyperparams']\n",
    "    param_search_space = models[model]['param_search']\n",
    "    search_results = HyperparameterSearch(model, \n",
    "                                          pipeline(hyperparams), \n",
    "                                          param_search_space, \n",
    "                                          verbose=False)\n",
    "    stop = time.time()\n",
    "    best_model = search_results.best_estimator_\n",
    "    y_pred = best_model.predict(X)\n",
    "    table.add_row([model, f'{stop - start:.4f} [s]', f'{accuracy_score(y, y_pred):.4f}'])\n",
    "    models[model]['best_params'] = search_results.best_params_\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9ad79-1420-416f-af63-4986424b57a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376505eb-1520-4b5e-86a0-bbbd9c54b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'LogisticRegression'\n",
    "pipeline = models[model]['pipeline']\n",
    "hyperparams = models[model]['hyperparams']\n",
    "\n",
    "best_hyperparams = hyperparams.copy()\n",
    "for hyperparam, value in models[model]['best_params'].items():\n",
    "    if 'model__' in hyperparam:\n",
    "        best_hyperparams[hyperparam.replace('model__', '')] = value.item() if type(value) == np.float64 else value\n",
    "    elif 'preproc__' in hyperparam:\n",
    "        if 'hash' in hyperparam:\n",
    "            best_hyperparams['n_features'] = value\n",
    "        elif 'robust' in hyperparam:\n",
    "            best_hyperparams['quantile_range'] = value\n",
    "print(hyperparams)\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cec5bef-e24f-4cc7-8343-e785620d8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00\n",
      "Accuracy CV by fold: [0.82122905 0.83146067 0.79213483 0.80898876 0.87078652]\n",
      "Accuracy mean CV: 0.8249  0.0264\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "scores = cross_val_score(\n",
    "    estimator=pipeline(best_hyperparams),\n",
    "    X=X, \n",
    "    y=y,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "stop = time.time()\n",
    "seconds_elapsed = stop - start\n",
    "time_format = str(dt.timedelta(seconds=int(seconds_elapsed)))\n",
    "    \n",
    "print(f'Training time: {time_format}')\n",
    "print(f'Accuracy CV by fold: {scores}')\n",
    "print(f'Accuracy mean CV: {scores.mean():.4f}  {scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458751b3-e018-496b-874f-9117eae2fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=107,\n",
    "                                                    stratify=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
