{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6234986e-88dd-44bc-b55d-8c3ec1b264e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dp\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from category_encoders import HashingEncoder, TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda47641-119f-4a62-bdce-444b862540e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E:/Datasets/titanic/wrangled dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732d8d34-38db-480e-89e0-0471b3e95c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w = pd.read_csv(f'{dataset_path}/train.csv')\n",
    "test_w = pd.read_csv(f'{dataset_path}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0d2dcf-6569-4a80-9f30-91e2fc23822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Family', 'Title',\n",
       "       'Deck', 'TicketPrefix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b8a66de-aa92-4415-aa72-8a99923be4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42877fa-9c51-4c33-b0db-e727b3acfc8b",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74efd9f-ac9b-4424-86f6-4b79f9bf6a22",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286709a9-bed1-4ae9-9a48-201de9cef5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cef45-f88b-45fa-8aa9-68296d153d5a",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb428e-e6a0-4ddc-a1f3-5c8c4bda0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "hyperparams = {\n",
    "}\n",
    "\n",
    "def logistic_regression_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    std_cols = ['Sex', 'Age']\n",
    "    ord_cols = ['Pclass', 'SibSp', 'Parch', 'Family']\n",
    "    rob_cols = ['Fare']\n",
    "    hash_cols = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols = ['Embarked']\n",
    "\n",
    "    ss_tf = StandardScaler()\n",
    "    ord_tf = OrdinalEncoder()\n",
    "    rb_tf = RobustScaler()\n",
    "    ohe_tf = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict')\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('standard', ss_tf, std_cols),\n",
    "        ('ordinal', ord_tf, ord_cols), #This is redundant but it is helpfull to maintain order\n",
    "        ('robust', rb_tf, rob_cols),\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ee3ef-b43c-4f98-bb05-39659668bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'preproc__robust__quantile_range': [(1.0,99.0), (5.0,95.0), (10.0,90.0), (25.0,75.0)],\n",
    "    'model__C': loguniform(1e-4, 1e4),\n",
    "    'model__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'model__solver': ['saga'],\n",
    "    'model__l1_ratio': uniform(0, 1),\n",
    "    'model__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'model__multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'model__tol': loguniform(1e-5, 1e-1),\n",
    "    'model__max_iter': [100, 200, 500]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b87f6e-56b7-4146-934c-955a4785462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['LogisticRegression'] = {}\n",
    "models['LogisticRegression']['pipeline'] = logistic_regression_pipeline\n",
    "models['LogisticRegression']['param_search'] = logistic_regression_param_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a825c-a23c-45b8-91e9-9cb0bde1a726",
   "metadata": {},
   "source": [
    "### RidgeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb3272-7fcb-4ac9-a185-e04e4dbbe3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f4ce412-cb5d-48d2-bfe2-2e2a10ab95f5",
   "metadata": {},
   "source": [
    "### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcc8a0-0144-442a-bbb1-0fceead7ec67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81763aa-3ffd-4129-9721-58dd6641cbad",
   "metadata": {},
   "source": [
    "### SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d8243-83b1-43a1-aa35-b9b9340d3da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fa373bc-2f0b-49e7-8c72-08f3202927d2",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f556f2d-fca6-4284-8f47-46f87e4cd5a4",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2fcf4-152f-41cb-b333-5bbd1ca9a78a",
   "metadata": {},
   "source": [
    "## Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc64c6e-73f3-4935-803d-5649076052e0",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ae53c-5d36-423e-9bb0-17763aa7e5bc",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d15f8-b84c-4029-975d-a154b33b76a7",
   "metadata": {},
   "source": [
    "This model is not affected too much by scaling, so I am going to leave untouch the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4642633-a89b-4356-bf0f-bb63f1c699e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "hyperparams = {\n",
    "    'n_features': 8,\n",
    "    'n_estimators' : 100,\n",
    "    'criterion' : 'gini',\n",
    "    'max_depth' : None,\n",
    "    'min_samples_split' : 2,\n",
    "    'min_samples_leaf' : 5,\n",
    "    'max_features' : 'sqrt',\n",
    "    'bootstrap' : True,\n",
    "    'n_jobs' : None\n",
    "}\n",
    "\n",
    "def random_forest_pipeline(params):\n",
    "    def df_to_dicts(X):\n",
    "        return X[hash_cols].astype(str).to_dict(orient='records')\n",
    "        \n",
    "    hash_cols   = ['Title', 'Deck', 'TicketPrefix']\n",
    "    cat_cols    = ['Embarked']\n",
    "    ohe_tf     = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    dict_tf = FunctionTransformer(df_to_dicts, validate=False)\n",
    "    hasher = FeatureHasher(n_features=params['n_features'], input_type='dict') #Replaces Hashing encoder\n",
    "    #hashing_tf = HashingEncoder(n_components=params['n_components'], cols=hash_cols)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        criterion=params['criterion'], \n",
    "        max_depth=params['max_depth'], \n",
    "        min_samples_split=params['min_samples_split'], \n",
    "        min_samples_leaf=params['min_samples_leaf'], \n",
    "        max_features=params['max_features'], \n",
    "        bootstrap=params['bootstrap'], \n",
    "        random_state=107\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('hash',  Pipeline([('to_dict', dict_tf), ('hasher', hasher)]), hash_cols),\n",
    "        ('ohe',    ohe_tf,    cat_cols),\n",
    "        ('num_passthrough', 'passthrough', make_column_selector(dtype_include=np.number)),\n",
    "    ], remainder='drop')\n",
    "    \n",
    "    return Pipeline(steps=[('preproc', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08a7f364-91f2-4e34-92c3-ee1355609771",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_param_search_space = {\n",
    "    'preproc__hash__hasher__n_features' : randint(4, 65),\n",
    "    'model__n_estimators': randint(100, 501),\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [None] + list(range(5, 51, 5)),\n",
    "    'model__min_samples_split': randint(2, 21),\n",
    "    'model__min_samples_leaf': randint(1, 11),\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5],\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'model__ccp_alpha': uniform(0.0, 0.01)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee593c8a-b1b8-4193-8f5b-70ddcb2c982a",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4d839-c3bb-4f9e-be4e-78076bfc749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c65a8bc-3926-485f-ac15-02a0c44ccf75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42e1311-356e-4fd5-867e-bde70a38e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "#X_test = test_w.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y = train_w['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a98a8-c4ad-4ae7-850c-d3e1a4109ab3",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d922c3-067f-467a-a59d-c31eeccbc087",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eed326-73e7-4044-aaaf-f4b3ea586aea",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b779d1b-846a-4775-a736-1409ae61fc50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcd043-f75f-4c72-bc1c-aaced22e1527",
   "metadata": {},
   "source": [
    "### GaussianNB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d019e-8580-4f81-b416-2436a71129c4",
   "metadata": {},
   "source": [
    "### CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a914c-cfc0-4b89-85a5-ded5814a7a2f",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a21456-b1a3-4fb1-bb71-79b2b94416e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa10de2e-2ecc-421e-bd42-8633fd1f8bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Mejores parámetros:\n",
      " {'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100, 'preproc__hash__hasher__n_features': 16}\n",
      "Mejor accuracy en CV: 0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Felpipe\\Trabajo\\Ciencias de datos en general\\KaggleChallenges\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0a71b2-6e5d-4d1d-98af-69188353fd97",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3715f3-f092-4023-98b3-bed4dcc2a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperparameterSearch(name, pipeline, param_distributions):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=107)\n",
    "    \n",
    "    rand_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=100,               \n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        random_state=107,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rand_search.fit(X, y)\n",
    "    \n",
    "    print(f'Best hyperparameters for {name}:\\n{rand_search.best_params_}')\n",
    "    print(f'Best accuracy for {name}: {rand_search.best_score_:.3f}')\n",
    "    \n",
    "    best_hyperparams = hyperparams.copy()\n",
    "    for hyperparam, value in rand_search.best_params_.items():\n",
    "        if 'model__' in hyperparam:\n",
    "            best_hyperparams[hyperparam.replace('model__', '')] = value\n",
    "        elif 'preproc__' in hyperparam:\n",
    "            best_hyperparams['n_features'] = value\n",
    "    \n",
    "    best_model = rand_search.best_estimator_\n",
    "    y_pred = best_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be43a73-c7a0-47f6-8318-f6d5181ac5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_test)\n",
    "y_pred = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276ea5e-a3ff-4a21-af54-5266d0b9705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy en test: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cec5bef-e24f-4cc7-8343-e785620d8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CV por pliegue: [0.75977654 0.79775281 0.79775281 0.7247191  0.82022472]\n",
      "Media de accuracy CV: 0.7800 ± 0.0338\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    estimator=pipe,         # tu pipeline (sin grid search)\n",
    "    X=X, \n",
    "    y=y,\n",
    "    cv=5,                   # número de pliegues\n",
    "    scoring='accuracy',     # métrica\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Accuracy CV por pliegue:\", scores)\n",
    "print(\"Media de accuracy CV: {:.4f} ± {:.4f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458751b3-e018-496b-874f-9117eae2fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=107,\n",
    "                                                    stratify=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
